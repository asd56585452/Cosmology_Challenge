# AGENTS.md for Cosmology_Challenge (PyTorch Version)

This document guides an autonomous agent (`jules`) in implementing, training, and evaluating a PyTorch-based baseline model for the Weak Gravitational Lensing Challenge. The objective is to create a solution that follows the data processing logic from the official `Phase_1_Startingkit_WL_PSAnalysis.ipynb` notebook and implements a more advanced CNN architecture.

## Goal

The agent's main objective is to perform the following steps:
1.  **Environment Setup**: Install PyTorch and other necessary libraries.
2.  **Data Processing**: Create a Python script to load, preprocess, and prepare the data for training, mirroring the logic in the provided starter notebook. This includes reshaping the data,add noise, handling labels, and creating PyTorch `DataLoader` objects.
3.  **Model Implementation**: Define a deep CNN model in PyTorch, translated from the provided Keras example. The model should output four values for the first phase: predicted means for Ωm and S8, and their corresponding uncertainties (σ).
4.  **Training and Evaluation**: Develop a training script that:
    * Uses the custom KL-divergence loss function required by the competition.
    * Trains the model on the preprocessed data.
    * Includes L2 regularization (`weight_decay`) in the optimizer.
    * Evaluates the model on a validation set to monitor performance (MSE, R², and the official score).
5.  **Prediction Generation**: Use the trained model to generate predictions on the test set and save them in the `result.json` format required for submission.
6. **zip and check**: Generate zip file and use the sample output `submissions/Submission_25-09-05-19-21.zip` that generated by `Phase_1_Startingkit_WL_PSAnalysis.ipynb` to check the final output format correctly.

---

## Phase 1: PyTorch Implementation of the Baseline Model

This phase details the step-by-step instructions for the agent to build and run the solution.

### **Step 1: Environment Setup**

The agent must ensure the environment is equipped with PyTorch and other essential data science libraries.

```bash
# Install required Python packages
pip install torch torchvision torchaudio numpy pandas scikit-learn matplotlib
```

### **Step 2: Create Data Processing Script**

The agent will create a new Python script named `data_loader.py`. This script will contain all the logic for loading and preparing the data, based on the `Phase_1_Startingkit_WL_PSAnalysis.ipynb` notebook.

### **Step 3: Create Model and Training Script**

The agent will now create the main script, `train_pytorch.py`, which will define the updated model architecture, the custom loss function, the training loop, and the prediction logic.

```python
#
# AGENT: Create the file `train_pytorch.py` with the following content.
#
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import json
from data_loader import get_data_loaders

# Define the Custom Loss Function (KL Divergence)
class KLLoss(nn.Module):
    def __init__(self, lambda_reg=0.01):
        super().__init__()
        self.lambda_reg = lambda_reg

    def forward(self, outputs, targets):
        mean_om, mean_s8 = outputs[:, 0], outputs[:, 1]
        log_var_om, log_var_s8 = outputs[:, 2], outputs[:, 3]
        true_om, true_s8 = targets[:, 0], targets[:, 1]

        var_om = torch.exp(log_var_om)
        var_s8 = torch.exp(log_var_s8)

        chi2_om = ((mean_om - true_om)**2) / var_om
        chi2_s8 = ((mean_s8 - true_s8)**2) / var_s8
        log_var_penalty = torch.sum(log_var_om + log_var_s8, dim=-1)
        mse_penalty = self.lambda_reg * torch.sum((outputs[:, :2] - targets)**2, dim=-1)
        loss = torch.mean(chi2_om + chi2_s8 + log_var_penalty + mse_penalty)
        return loss

# Define the updated CNN Model Architecture (PyTorch version of the provided Keras model)
class WeakLensingCNN(nn.Module):
    def __init__(self, nf=32):
        super().__init__()

        def conv_block(in_channels, out_channels, kernel_size=3, padding=0):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            )

        self.model = nn.Sequential(
            # Block 1
            conv_block(1, nf), conv_block(nf, nf), nn.AvgPool2d(2),
            # Block 2
            conv_block(nf, 2*nf), conv_block(2*nf, 2*nf), nn.AvgPool2d(2),
            # Block 3
            conv_block(2*nf, 4*nf), conv_block(4*nf, 2*nf, kernel_size=1), conv_block(2*nf, 4*nf), nn.AvgPool2d(2),
            # Block 4
            conv_block(4*nf, 8*nf), conv_block(8*nf, 4*nf, kernel_size=1), conv_block(4*nf, 8*nf), nn.AvgPool2d(2),
            # Block 5
            conv_block(8*nf, 16*nf), conv_block(16*nf, 8*nf, kernel_size=1), conv_block(8*nf, 16*nf), nn.AvgPool2d(2),
            # Block 6
            conv_block(16*nf, 16*nf), conv_block(16*nf, 8*nf, kernel_size=1), conv_block(16*nf, 16*nf),
            conv_block(16*nf, 8*nf, kernel_size=1), conv_block(8*nf, 16*nf),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(16*nf, 4) # Final output: mean_om, mean_s8, log_var_om, log_var_s8
        )

    def forward(self, x):
        return self.model(x)
```

### **Step 4: Execute the Training and Prediction**

The agent will run the `train_pytorch.py` script to perform all necessary actions: data loading, training, and prediction generation.

---

## Verification

The agent should verify the success of the process by checking for the following:
- The existence of the final prediction file (`output/result.json`) and file (`submissions/Submission_{time}.zip`)
- The log output from the training script, which should show the training and validation loss decreasing over epochs.
- The format of `result.json` must match the competition's submission requirements.

This `AGENTS.md` provides a complete, self-contained plan for `jules` to tackle the competition using a modern deep learning framework and following best practices for data handling as demonstrated in the official starting materials.